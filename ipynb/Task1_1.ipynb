{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da32404f-e371-4151-9939-fe36be1c624a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca99bc4b-15e3-4398-83aa-5fbf30cefd55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad944682-dc0c-4d11-95ed-4af4beda54ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('test').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e3b37e0-22d0-4e45-bb48-29213c3224a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=6882184093748701#setting/sparkui/0213-084946-9dfs7hxi/driver-4631430601916881909\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=6882184093748701#setting/sparkui/0213-084946-9dfs7hxi/driver-4631430601916881909\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0f6b165-e707-4390-9955-861531e0a8e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile(\"dbfs:/FileStore/shared_uploads/pratikpj545@gmail.com/text.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7985a20e-e8c6-4097-85f8-cead9a0e784c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of words in a file is:  64\n"
     ]
    }
   ],
   "source": [
    "r1 = rdd.flatMap(lambda x: x.split(\" \"))\n",
    "r1.collect()\n",
    "print(\"count of words in a file is: \",r1.count())\n",
    "# Count the number of words in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2187705e-3802-45c0-a592-c75c162433bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique word is:  57\n"
     ]
    }
   ],
   "source": [
    "unique = rdd.flatMap(lambda x: x.split(\" \")).distinct()\n",
    "print(\"Count of unique word is: \",unique.count())\n",
    "# Count of unique word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27f403ac-b9e4-4117-b68c-6b9af1edd3a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that starts with a letter a:\nand\na\nand\nauthorship\nas\narticle\nand\naside\nare\nasks\nas…\na\n"
     ]
    }
   ],
   "source": [
    "fltr = rdd.flatMap(lambda x: x.split(\" \")).filter(lambda w: w.startswith(\"a\") or w.startswith(\"A\"))\n",
    "\n",
    "print(\"Words that starts with a letter a:\")\n",
    "for w in fltr.collect():\n",
    "    print(w)\n",
    "# Find words that starts with a letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "548219b7-c8a2-49a0-95d2-576f9ef37ec9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction : 1\ndistraction : 1\nthough : 1\nis, : 1\nWorld : 1\nWide : 1\nis : 2\nprimarily : 1\nconduit : 1\ninformation. : 1\nwriting : 1\nauthorship : 1\nmore : 2\npronounced : 1\nthan : 1\never. : 1\nIt’s : 1\nevident : 1\nin : 1\nvery : 1\nway : 1\nnew : 1\nas : 1\naside : 1\nare : 1\nnamed. : 1\nHTML5 : 1\nus : 1\ntreat : 1\nHTML : 1\nwell, : 1\nBursting : 1\nwith : 1\nimagery, : 1\nmotion, : 1\nand : 3\nit : 1\ntoday’s : 1\nWeb : 1\nstill : 1\na : 2\nfor : 1\ntextual : 1\nIn : 1\nHTML5, : 1\nthe : 3\nfocus : 1\non : 1\nthat : 1\nelements : 1\nsuch : 1\narticle : 1\nasks : 1\nto : 1\ndocument : 1\nas… : 1\ndocument. : 1\n"
     ]
    }
   ],
   "source": [
    "occu = rdd.flatMap(lambda x: x.split(\" \")).map(lambda w: (w, 1)).reduceByKey(lambda x, y: x+y)\n",
    "\n",
    "for wrd, cnt in occu.collect():\n",
    "    print(wrd, \":\", cnt)\n",
    "#Find number of occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "090063f0-4296-41e9-b0bd-39e48fc425bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of sentences in text is:  5\n"
     ]
    }
   ],
   "source": [
    "sentence = rdd.flatMap(lambda x: x.split(\".\"))\n",
    "print(\"Count of sentences in text is: \",sentence.count())\n",
    "# Print how many sentences in text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52b4cb9a-f19c-4127-891a-db718b8378d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[23]: ['HTML5,', 'HTML5', 'HTML']"
     ]
    }
   ],
   "source": [
    "vowel = ['a', 'e', 'i', 'o', 'u']\n",
    "\n",
    "def is_vowel(word):\n",
    "    for char in word:\n",
    "        if char.lower() in vowel:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "filtered_words = rdd.flatMap(lambda x: x.split(\" \")).filter(has_vowel)\n",
    "filtered_words.collect() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "194317db-fb35-4482-89fa-30733c54adea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Task1_1",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
